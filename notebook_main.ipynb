{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter에서 가상 환경 인식시키는 방법 \n",
    "1. 폴더 생성 후 가상환경을 생성\n",
    "\n",
    "   ```bash\n",
    "   mkdir llm_project\n",
    "   cd llm_project\n",
    "    \n",
    "   # git 저장소 복사\n",
    "   git clone https://github.com/kdu9303/news_classifier_model.git\n",
    "    \n",
    "   # 가상환경 생성\n",
    "   python -m venv venv\n",
    "    \n",
    "   # 3.10버전으로 설치\n",
    "   python3.10 -m venv venv\n",
    "\n",
    "   ```\n",
    "3. 가상환경 activate 후 requirements.txt를 통해 패키지 설치\n",
    "\n",
    "   ```bash\n",
    "   pip install -r requirements.txt --upgrade\n",
    "    mkdir llm_project\n",
    "    cd llm_project\n",
    "   mkdir llm_project\n",
    "   cd llm_project\n",
    "    \n",
    "   # 가상환경 생성\n",
    "   python -m venv venv\n",
    "    \n",
    "   # 3.10버전으로 설치\n",
    "   python3.10 -m venv venv\n",
    "   ```\n",
    "3. 가상환경 activate 후 requirements.txt를 통해 패키지 설치\n",
    "\n",
    "   ```bash\n",
    "    pip install -r requirements.txt --upgrade\n",
    "    ```\n",
    "5. 가상환경과 Jypyter kernel 연결 \n",
    "\n",
    "   ```bash\n",
    "   # python -m ipykernel install --user --name \"가상환경이름\" --display-name \"노트북에 표시할 이름\"\n",
    "   python -m ipykernel install --user --name venv --display-name llm_venv\n",
    "    ```\n",
    "7. Jupyter lab 실행\n",
    "\n",
    "   ```bash\n",
    "   jupyter lab\n",
    "    ```",
    "   pip install -r requirements.txt --upgrade\n",
    "   ```\n",
    "5. 가상환경과 Jypyter kernel 연결 \n",
    "\n",
    "   ```bash\n",
    "   # python -m ipykernel install --user --name \"가상환경이름\" --display-name \"노트북에 표시할 이름\"\n",
    "   python -m ipykernel install --user --name venv --display-name llm_venv\n",
    "   ```\n",
    "7. Jupyter lab 실행\n",
    "\n",
    "   ```bash\n",
    "   jupyter lab\n",
    "   ```"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import warnings\n",
    "import aiocsv\n",
    "import aiofiles\n",
    "import tiktoken\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "from functools import wraps\n",
    "from typing import Any, Coroutine, Generator, AsyncGenerator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# text 전처리\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.document_loaders.excel import UnstructuredExcelLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import (\n",
    "    create_retrieval_chain,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 클래스 정의\n",
    "- 훈련 데이터의 폴더와 Input용 데이터가 담긴 폴더의 경로를 인자로 넘겨야합니다.\n",
    "- Input 형태는 csv와 xlsx 엑셀파일만 가능합니다.\n",
    "    - 텍스트 형태의 데이터는 기사 단위(row단위)로 프로세스가 어려우므로 제외\n",
    "- 사용 가능 모델\n",
    "    - gpt-3.5-turbo\n",
    "    - gpt-4-turbo\n",
    "    - claude-2.1\n",
    "    - claude-3-haiku-20240307\n",
    "- 훈련 데이터 가능 확장자\n",
    "    - pdf, docx, txt, xlsx, csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_timer(func):\n",
    "    @wraps(func)\n",
    "    async def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # call the decorated function\n",
    "        result = await func(*args, **kwargs)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        if func.__name__ == \"main\":\n",
    "            print(f\"----------------------------------------\")\n",
    "            print(f\"---------- Main 함수 실행 --------------\")\n",
    "            print(f\"총 실행 시간: {execution_time:.3f}초\")\n",
    "            print(f\"----------------------------------------\")\n",
    "        else:\n",
    "            print(f\"----------------------------------------\")\n",
    "            print(f\"실행 시간: {execution_time:.3f}초\")\n",
    "            print(f\"----------------------------------------\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class LlmArticleClassifier:\n",
    "    def __init__(self, train_dir_path: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        self.train_dir_path = train_dir_path\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    async def async_get_input_data_from_files(\n",
    "        self, input_dir_path\n",
    "    ) -> AsyncGenerator[str, None]:\n",
    "        for file_name in glob.glob(input_dir_path + \"/*\"):\n",
    "            try:\n",
    "                if \".xlsx\" in file_name:\n",
    "                    data = pd.read_excel(file_name)\n",
    "                elif \".csv\" in file_name:\n",
    "                    data = pd.read_csv(file_name)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                for _, row in data.iterrows():\n",
    "                    row_dict = row.to_dict()\n",
    "                    row_str = \"\\n\".join(f'\"{k}\": \"{v}\"' for k, v in row_dict.items())\n",
    "                    yield row_str\n",
    "\n",
    "            except Exception:\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    def sync_get_input_data_from_files(self) -> Generator[str, None, None]:\n",
    "        # formatted_data_strings = []\n",
    "\n",
    "        for file_name in glob.glob(self.input_dir_path + \"/*\"):\n",
    "            try:\n",
    "                if \".xlsx\" in file_name:\n",
    "                    data = pd.read_excel(file_name)\n",
    "                elif \".csv\" in file_name:\n",
    "                    data = pd.read_csv(file_name)\n",
    "\n",
    "                for _, row in data.iterrows():\n",
    "                    row_dict = row.to_dict()\n",
    "                    row_str = \"\\n\".join(f'\"{k}\": \"{v}\"' for k, v in row_dict.items())\n",
    "                    # formatted_data_strings.append(row_str)\n",
    "                    yield row_str\n",
    "\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "        # return formatted_data_strings\n",
    "\n",
    "    def get_train_data_from_files(self) -> list[Document]:\n",
    "        doc_list = []\n",
    "\n",
    "        for file_name in glob.glob(self.train_dir_path + \"/*\"):\n",
    "            print(f\"Uploaded {file_name}\")\n",
    "\n",
    "            if \".pdf\" in file_name:\n",
    "                loader = PyPDFLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".docx\" in file_name:\n",
    "                loader = Docx2txtLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".txt\" in file_name:\n",
    "                loader = TextLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".xlsx\" in file_name:\n",
    "                loader = UnstructuredExcelLoader(file_name, mode=\"elements\")\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".csv\" in file_name:\n",
    "                loader = CSVLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            doc_list.extend(documents)\n",
    "\n",
    "        return doc_list\n",
    "\n",
    "    def tiktoken_len(self, text: str) -> int:\n",
    "        tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens = tokenizer.encode(text)\n",
    "        return len(tokens)\n",
    "\n",
    "    def get_text_chunks(self) -> list[Document]:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1024, chunk_overlap=100, length_function=self.tiktoken_len\n",
    "        )\n",
    "        text = self.get_train_data_from_files()\n",
    "        chunks = text_splitter.split_documents(text)\n",
    "        return chunks\n",
    "\n",
    "    async def get_vectorstore(self) -> Coroutine[Any, Any, FAISS]:\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "        text_chunks = self.get_text_chunks()\n",
    "        vectordb = await FAISS.afrom_documents(text_chunks, embeddings)\n",
    "        return vectordb\n",
    "\n",
    "    def set_templetes(self):\n",
    "        document_template = f\"\"\"\n",
    "            너의 역할은 주어진 뉴스 기사나 리포트를 분석하고 제공된 Output 형식의 카테고리 분류 설명에 따라 \n",
    "            입력 기사를 카테고리별로 분류하는 역할이야.\n",
    "            결과를 출력할때는 Markdown에서 글씨를 보기 쉽게 문장 혹은 단위별로 prettify를 적용해서 출력해줘.\n",
    "            \n",
    "            리포트 혹은 뉴스의 내용과 Output 형식은 백틱(```)안에 주어진다.\n",
    "            예제 리포트에 포함된 내용은 결과에 Return하지 않는다.\n",
    "            \n",
    "            예제 리포트:\n",
    "            {{context}}\n",
    "            \n",
    "            ```\n",
    "            {{input}}\n",
    "            ```\n",
    "            \"\"\"\n",
    "        document_prompt = PromptTemplate(\n",
    "            template=document_template, input_variables=[\"input\"]\n",
    "        )\n",
    "\n",
    "        return document_prompt\n",
    "\n",
    "    async def get_create_retrieval_chain(self, temperature: float = 0.0):\n",
    "\n",
    "        if \"gpt\" in self.model:\n",
    "            llm = ChatOpenAI(\n",
    "                api_key=os.getenv(\"open_ai_key\"),\n",
    "                model_name=self.model,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "        elif \"claude\" in self.model:\n",
    "            llm = ChatAnthropic(\n",
    "                api_key=os.getenv(\"antrophic_key\"),\n",
    "                model_name=self.model,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever 옵션\n",
    "        as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5})\n",
    "        as_retriever(search_kwargs={\"k\": 3})\n",
    "        as_retriever(search_type=\"mmr\")\n",
    "        \"\"\"\n",
    "        vectorstore = await self.get_vectorstore()\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        document_prompt = self.set_templetes()\n",
    "\n",
    "        combine_docs_chain = create_stuff_documents_chain(llm, document_prompt)\n",
    "        retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "        return retrieval_chain\n",
    "\n",
    "    @async_timer\n",
    "    async def process_llm(self, query: str) -> str:\n",
    "        chain = await self.get_create_retrieval_chain()\n",
    "        result = await chain.ainvoke({\"input\": query})\n",
    "        print(result[\"answer\"])\n",
    "\n",
    "        return result\n",
    "\n",
    "    @async_timer\n",
    "    async def process_llm_batch(self, queries: list[str]) -> list[dict[str, str]]:\n",
    "        chain = await self.get_create_retrieval_chain()\n",
    "        results = await chain.abatch([{\"input\": query} for query in queries])\n",
    "        for result in results:\n",
    "            # print(f\"Query: {result['input']}\")\n",
    "            print(result['answer'])\n",
    "            print()\n",
    "        return results    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_to_csv(results: list[dict[str, str]]):\n",
    "\n",
    "    output_dir = \"./output_data\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, \"results.csv\")\n",
    "\n",
    "    async with aiofiles.open(\n",
    "        output_file, mode=\"w\", encoding=\"utf-8-sig\", newline=\"\"\n",
    "    ) as afp:\n",
    "        writer = aiocsv.AsyncWriter(afp, dialect=\"unix\")\n",
    "        # header\n",
    "        await writer.writerow([\"query\", \"answer\"])\n",
    "\n",
    "        # rows\n",
    "        for result in results:\n",
    "            await writer.writerow([result[\"input\"], result[\"answer\"]])\n",
    "\n",
    "    print(f\"결과가 '{output_file}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main 함수\n",
    "main 함수에서는 LlmArticleClassifier 클래스를 초기화하고, 입력 데이터를 가져와서 process_llm 메서드를 실행하는 방식으로 사용됩니다. 코드에서는 비동기 방식으로 데이터를 처리하고, 일정한 크기의 청크로 나누어 병렬로 처리하는 방식을 사용하고 있습니다.\n",
    "\n",
    "### main 함수의 동작 과정:\n",
    "\n",
    "1. LlmArticleClassifier 클래스를 초기화\n",
    "   - train_dir_path -> 훈련용 데이터 폴더 위치를 인자로 전달\n",
    "2. LlmArticleClassifier.async_get_input_data_from_files()\n",
    "   - 폴더에 있는 파일의 row단위를 input형태로 변환\n",
    "   - input_dir_path -> Input 폴더의 위치를 인자로 전달\n",
    "3. data_generator로부터 일정한 크기의 묶음으로 나누어 병렬로 처리\n",
    "   - chunk -> 병렬처리용 Thread 개수를 설정\n",
    "4. 각 청크에 대해 병렬로 결과 처리\n",
    "   - write_to_csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@async_timer\n",
    "async def main():\n",
    "    llm = LlmArticleClassifier(train_dir_path=\"./train_data\", model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    # 폴더 내의 모든 엑셀파일 인식\n",
    "    data_generator = llm.async_get_input_data_from_files(\n",
    "        input_dir_path=\"./input_data\",\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    chunk_size = 4  # 한 번에 처리할 chunk 크기\n",
    "    batch_queries = []\n",
    "    async for query in data_generator:\n",
    "        batch_queries.append(query)\n",
    "        if len(batch_queries) == chunk_size:\n",
    "            results.extend(await llm.process_llm_batch(batch_queries))\n",
    "            batch_queries.clear()\n",
    "\n",
    "    # 잔여 task가 있을경우 처리\n",
    "    if batch_queries:\n",
    "        results.extend(await llm.process_llm_batch(batch_queries))\n",
    "    \n",
    "    await write_to_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploaded .<span style=\"color: #800080; text-decoration-color: #800080\">/train_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">training_data.txt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploaded .\u001b[35m/train_data/\u001b[0m\u001b[95mtraining_data.txt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">제목: <span style=\"color: #008000; text-decoration-color: #008000\">'메가존클라우드, 데이터브릭스 최고 등급 ‘엘리트’ 파트너 선정'</span>\n",
       "언론사: 한국경제TV\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:57:28</span>\n",
       "대상기업: 메가존클라우드\n",
       "내용: \n",
       "    - 내용 소제목: 데이터브릭스 최고 등급 ‘엘리트’ 파트너 선정\n",
       "    - 내용 요약: 메가존클라우드가 데이터브릭스의 최고 등급 <span style=\"color: #008000; text-decoration-color: #008000\">'엘리트'</span> 파트너로 선정되었으며, 이는 고객의 성공적인 \n",
       "디지털 전환을 이끈 파트너에 부여되는 등급이다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 투자\n",
       "            - 수치: 2000억원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 기업가치\n",
       "            - 수치: 8000억원\n",
       "    - 내용 소제목: 파트너십 협력\n",
       "    - 내용 요약: 메가존클라우드는 데이터브릭스와 파트너십을 체결하여 데이터브릭스 솔루션을 기반으로 기술검증, \n",
       "고객사 대상 핸즈온 세션 지원, 데이터 전환 사업 구축 등을 진행하고 있으며, 최고 파트너 등급 <span style=\"color: #008000; text-decoration-color: #008000\">'엘리트'</span> 선정을 통해 \n",
       "데이터와 AI의 활용을 가속화할 계획이다.\n",
       "    - 내용 소제목: 회사 배경\n",
       "    - 내용 요약: 메가존클라우드는 2700여명의 클라우드 전문 인력을 보유하고 있으며, 국내 클라우드 MSP업계 최초의 \n",
       "유니콘 기업으로 등극하였고, 2023년에는 1조5106억원의 매출을 달성하였다.해외에도 미국, 일본, 캐나다, 호주, 중국 \n",
       "상해·북경, 베트남, 홍콩, 싱가포르 등 8개국에서 현지 법인을 운영하고 있다.\n",
       "    - 내용 소제목: 파트너십 강화\n",
       "    - 내용 요약: 메가존클라우드와 데이터브릭스는 더 많은 한국 기업들이 데이터브릭스 데이터 인텔리전스 플랫폼을 \n",
       "활용할 수 있도록 파트너십을 더욱 강화할 예정이다.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "제목: \u001b[32m'메가존클라우드, 데이터브릭스 최고 등급 ‘엘리트’ 파트너 선정'\u001b[0m\n",
       "언론사: 한국경제TV\n",
       "발행일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m09:57:28\u001b[0m\n",
       "대상기업: 메가존클라우드\n",
       "내용: \n",
       "    - 내용 소제목: 데이터브릭스 최고 등급 ‘엘리트’ 파트너 선정\n",
       "    - 내용 요약: 메가존클라우드가 데이터브릭스의 최고 등급 \u001b[32m'엘리트'\u001b[0m 파트너로 선정되었으며, 이는 고객의 성공적인 \n",
       "디지털 전환을 이끈 파트너에 부여되는 등급이다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 투자\n",
       "            - 수치: 2000억원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 기업가치\n",
       "            - 수치: 8000억원\n",
       "    - 내용 소제목: 파트너십 협력\n",
       "    - 내용 요약: 메가존클라우드는 데이터브릭스와 파트너십을 체결하여 데이터브릭스 솔루션을 기반으로 기술검증, \n",
       "고객사 대상 핸즈온 세션 지원, 데이터 전환 사업 구축 등을 진행하고 있으며, 최고 파트너 등급 \u001b[32m'엘리트'\u001b[0m 선정을 통해 \n",
       "데이터와 AI의 활용을 가속화할 계획이다.\n",
       "    - 내용 소제목: 회사 배경\n",
       "    - 내용 요약: 메가존클라우드는 2700여명의 클라우드 전문 인력을 보유하고 있으며, 국내 클라우드 MSP업계 최초의 \n",
       "유니콘 기업으로 등극하였고, 2023년에는 1조5106억원의 매출을 달성하였다.해외에도 미국, 일본, 캐나다, 호주, 중국 \n",
       "상해·북경, 베트남, 홍콩, 싱가포르 등 8개국에서 현지 법인을 운영하고 있다.\n",
       "    - 내용 소제목: 파트너십 강화\n",
       "    - 내용 요약: 메가존클라우드와 데이터브릭스는 더 많은 한국 기업들이 데이터브릭스 데이터 인텔리전스 플랫폼을 \n",
       "활용할 수 있도록 파트너십을 더욱 강화할 예정이다.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">제목: <span style=\"color: #008000; text-decoration-color: #008000\">'KT스카이라이프, 1분기 영업익 29억 원…전년比 82%↓'</span>\n",
       "언론사: 서울경제\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:03</span>\n",
       "대상기업: KT스카이라이프\n",
       "내용: \n",
       "    - 내용 소제목: 1분기 영업실적\n",
       "    - 내용 요약: KT스카이라이프는 올해 1분기에 대폭 축소된 영업이익을 기록하며 부진한 실적을 보였다. 매출액은 소폭 \n",
       "증가했지만 이익은 크게 감소했다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 영업이익\n",
       "            - 수치: 29억 원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 매출액\n",
       "            - 수치: 2544억 원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 당기순이익\n",
       "            - 수치: 13억 원\n",
       "    - 내용 소제목: 영업이익 감소 이유\n",
       "    - 내용 요약: 영업이익이 줄어든 이유는 콘텐츠 투자 비용 증가와 방송 발전 기금, 프로그램 사용료 증가 등이 영향을 \n",
       "끼쳤다.\n",
       "    - 내용 소제목: 매출액 증가\n",
       "    - 내용 요약: 매출액이 증가한 이유는 인터넷과 모바일 가입자의 지속적인 증가로 전체 유지 가입자 수가 확보되었기 \n",
       "때문이다.\n",
       "    - 내용 소제목: ENA 성장\n",
       "    - 내용 요약: KT스카이라이프의 방송 채널인 ENA가 성장하며 시청률 순위에서 상승하고 광고 수익도 증가하고 있다.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "제목: \u001b[32m'KT스카이라이프, 1분기 영업익 29억 원…전년比 82%↓'\u001b[0m\n",
       "언론사: 서울경제\n",
       "발행일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m09:56:03\u001b[0m\n",
       "대상기업: KT스카이라이프\n",
       "내용: \n",
       "    - 내용 소제목: 1분기 영업실적\n",
       "    - 내용 요약: KT스카이라이프는 올해 1분기에 대폭 축소된 영업이익을 기록하며 부진한 실적을 보였다. 매출액은 소폭 \n",
       "증가했지만 이익은 크게 감소했다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 영업이익\n",
       "            - 수치: 29억 원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 매출액\n",
       "            - 수치: 2544억 원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 당기순이익\n",
       "            - 수치: 13억 원\n",
       "    - 내용 소제목: 영업이익 감소 이유\n",
       "    - 내용 요약: 영업이익이 줄어든 이유는 콘텐츠 투자 비용 증가와 방송 발전 기금, 프로그램 사용료 증가 등이 영향을 \n",
       "끼쳤다.\n",
       "    - 내용 소제목: 매출액 증가\n",
       "    - 내용 요약: 매출액이 증가한 이유는 인터넷과 모바일 가입자의 지속적인 증가로 전체 유지 가입자 수가 확보되었기 \n",
       "때문이다.\n",
       "    - 내용 소제목: ENA 성장\n",
       "    - 내용 요약: KT스카이라이프의 방송 채널인 ENA가 성장하며 시청률 순위에서 상승하고 광고 수익도 증가하고 있다.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```\n",
       "제목: <span style=\"color: #008000; text-decoration-color: #008000\">\"'인공지능?' '아니 공감지능!'…LG 올레드 에보, 50년 전 김환기 작품 소환\"</span>\n",
       "언론사: 데일리안\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:10</span>\n",
       "대상기업: LG전자\n",
       "내용: \n",
       "    - 내용 소제목: LG 올레드 에보 소개\n",
       "    - 내용 요약: LG전자의 <span style=\"color: #008000; text-decoration-color: #008000\">'공감지능(AI)'</span> TV <span style=\"color: #008000; text-decoration-color: #008000\">'LG 올레드 에보'</span>가 한국 대표 미술가 <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">고</span><span style=\"font-weight: bold\">(</span>故<span style=\"font-weight: bold\">)</span> 김환기 화백의 작품을 미국 \n",
       "뉴욕에 선보이는 <span style=\"color: #008000; text-decoration-color: #008000\">'디지털 캔버스'</span>로 활약하고 있다. 김환기의 대표작을 재해석한 미디어아트가 전시되며, LG 올레드 에보는\n",
       "AI 화질‧음질 프로세서인 <span style=\"color: #008000; text-decoration-color: #008000\">'알파11'</span>을 탑재하여 사용자에게 차별화된 고객경험을 제공한다.\n",
       "    - 내용 소제목: 뉴욕 전시\n",
       "    - 내용 요약: LG전자는 <span style=\"color: #008000; text-decoration-color: #008000\">'프리즈 뉴욕'</span>에서 추상미술의 거장 김환기 화백의 작품을 재해석한 미디어아트 5점을 2024년형\n",
       "LG 올레드 에보로 선보인다. 김환기의 작품을 미디어아트로 표현하며, 뉴욕한국문화원에서도 LG 올레드 에보를 통해 김환기\n",
       "작품 관련 미디어아트가 전시된다.\n",
       "    - 내용 소제목: LG 올레드 에보 기능\n",
       "    - 내용 요약: LG 올레드 에보는 AI 화질‧음질 프로세서 <span style=\"color: #008000; text-decoration-color: #008000\">'알파11'</span>을 탑재하여 사용자의 취향을 스스로 파악하고 공간 \n",
       "사운드를 풍성하게 제공한다. AI 챗봇 기능을 통해 사용자의 목소리를 구별하고 맞춤 콘텐츠 추천 및 화질 설정을 \n",
       "제공한다.\n",
       "```\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```\n",
       "제목: \u001b[32m\"'인공지능?' '아니 공감지능!'…LG 올레드 에보, 50년 전 김환기 작품 소환\"\u001b[0m\n",
       "언론사: 데일리안\n",
       "발행일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m10:00:10\u001b[0m\n",
       "대상기업: LG전자\n",
       "내용: \n",
       "    - 내용 소제목: LG 올레드 에보 소개\n",
       "    - 내용 요약: LG전자의 \u001b[32m'공감지능\u001b[0m\u001b[32m(\u001b[0m\u001b[32mAI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m TV \u001b[32m'LG 올레드 에보'\u001b[0m가 한국 대표 미술가 \u001b[1;35m고\u001b[0m\u001b[1m(\u001b[0m故\u001b[1m)\u001b[0m 김환기 화백의 작품을 미국 \n",
       "뉴욕에 선보이는 \u001b[32m'디지털 캔버스'\u001b[0m로 활약하고 있다. 김환기의 대표작을 재해석한 미디어아트가 전시되며, LG 올레드 에보는\n",
       "AI 화질‧음질 프로세서인 \u001b[32m'알파11'\u001b[0m을 탑재하여 사용자에게 차별화된 고객경험을 제공한다.\n",
       "    - 내용 소제목: 뉴욕 전시\n",
       "    - 내용 요약: LG전자는 \u001b[32m'프리즈 뉴욕'\u001b[0m에서 추상미술의 거장 김환기 화백의 작품을 재해석한 미디어아트 5점을 2024년형\n",
       "LG 올레드 에보로 선보인다. 김환기의 작품을 미디어아트로 표현하며, 뉴욕한국문화원에서도 LG 올레드 에보를 통해 김환기\n",
       "작품 관련 미디어아트가 전시된다.\n",
       "    - 내용 소제목: LG 올레드 에보 기능\n",
       "    - 내용 요약: LG 올레드 에보는 AI 화질‧음질 프로세서 \u001b[32m'알파11'\u001b[0m을 탑재하여 사용자의 취향을 스스로 파악하고 공간 \n",
       "사운드를 풍성하게 제공한다. AI 챗봇 기능을 통해 사용자의 목소리를 구별하고 맞춤 콘텐츠 추천 및 화질 설정을 \n",
       "제공한다.\n",
       "```\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">제목: <span style=\"color: #008000; text-decoration-color: #008000\">'팹리스 업체'</span> 퓨리오사AI, 2000억 투자 유치 추진\n",
       "언론사: thebell\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20230119</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:05:04</span>\n",
       "대상기업: 퓨리오사AI\n",
       "내용: \n",
       "    - 내용 소제목: 퓨리오사AI, 최대 2000억 투자 유치 추진\n",
       "    - 내용 요약: 퓨리오사AI가 최대 2000억원 규모의 투자 유치를 추진 중이며, 기업가치는 8000억원 이상이다. 산은과 \n",
       "DSC인베스트먼트가 투자에 참여할 예정이며, 후속 투자 가능성이 열려있다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 시리즈C 투자 유치 규모\n",
       "            - 수치: 2000억원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 기업가치\n",
       "            - 수치: 8000억원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 이전 유치 규모\n",
       "            - 수치: 800억원\n",
       "\n",
       "```\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'국제민간항공기구-에콰도르 키토공항과 협력확대'</span>\n",
       "생성일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:03</span>\n",
       "세부분류: 산업/재계\n",
       "언론사: 파이낸셜뉴스\n",
       "url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://n.news.naver.com/mnews/article/014/0005179679</span>\n",
       "기사_내용: 인천국제공항공사와 <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">국제민간항공기구</span><span style=\"font-weight: bold\">(</span>ICAO<span style=\"font-weight: bold\">)</span>가 협력을 확대하는 내용이다. 이번 MOU 체결을 통해 공사는 \n",
       "직원들의 해외 직무수행 경험 기회를 확대하여 향후 해외사업 전문 인력으로 육성한다는 방침이다.\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "제목: \u001b[32m'팹리스 업체'\u001b[0m 퓨리오사AI, 2000억 투자 유치 추진\n",
       "언론사: thebell\n",
       "발행일자: \u001b[1;36m20230119\u001b[0m \u001b[1;92m08:05:04\u001b[0m\n",
       "대상기업: 퓨리오사AI\n",
       "내용: \n",
       "    - 내용 소제목: 퓨리오사AI, 최대 2000억 투자 유치 추진\n",
       "    - 내용 요약: 퓨리오사AI가 최대 2000억원 규모의 투자 유치를 추진 중이며, 기업가치는 8000억원 이상이다. 산은과 \n",
       "DSC인베스트먼트가 투자에 참여할 예정이며, 후속 투자 가능성이 열려있다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 시리즈C 투자 유치 규모\n",
       "            - 수치: 2000억원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 기업가치\n",
       "            - 수치: 8000억원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 이전 유치 규모\n",
       "            - 수치: 800억원\n",
       "\n",
       "```\n",
       "\u001b[32m'국제민간항공기구-에콰도르 키토공항과 협력확대'\u001b[0m\n",
       "생성일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m10:00:03\u001b[0m\n",
       "세부분류: 산업/재계\n",
       "언론사: 파이낸셜뉴스\n",
       "url: \u001b[4;94mhttps://n.news.naver.com/mnews/article/014/0005179679\u001b[0m\n",
       "기사_내용: 인천국제공항공사와 \u001b[1;35m국제민간항공기구\u001b[0m\u001b[1m(\u001b[0mICAO\u001b[1m)\u001b[0m가 협력을 확대하는 내용이다. 이번 MOU 체결을 통해 공사는 \n",
       "직원들의 해외 직무수행 경험 기회를 확대하여 향후 해외사업 전문 인력으로 육성한다는 방침이다.\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">실행 시간: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.</span>227초\n",
       "</pre>\n"
      ],
      "text/plain": [
       "실행 시간: \u001b[1;36m24.\u001b[0m227초\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">결과가 <span style=\"color: #008000; text-decoration-color: #008000\">'./output_data/results.csv'</span>에 저장되었습니다.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "결과가 \u001b[32m'./output_data/results.csv'\u001b[0m에 저장되었습니다.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---------- Main 함수 실행 --------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---------- Main 함수 실행 --------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">총 실행 시간: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.</span>413초\n",
       "</pre>\n"
      ],
      "text/plain": [
       "총 실행 시간: \u001b[1;36m24.\u001b[0m413초\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
