{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter에서 가상 환경 인식시키는 방법\n",
    "\n",
    "1. 폴더 생성 후 가상환경을 생성\n",
    "\n",
    "   ```bash\n",
    "   mkdir llm_project\n",
    "   cd llm_project\n",
    "\n",
    "   # git 저장소 복사\n",
    "   git clone https://github.com/kdu9303/news_classifier_model.git\n",
    "\n",
    "   # 가상환경 생성\n",
    "   python -m venv venv\n",
    "\n",
    "   # 3.10버전으로 설치\n",
    "   python3.10 -m venv venv\n",
    "\n",
    "   ```\n",
    "\n",
    "2. 가상환경 activate 후 requirements.txt를 통해 패키지 설치\n",
    "\n",
    "   ```bash\n",
    "   pip install -r requirements.txt --upgrade\n",
    "   ```\n",
    "\n",
    "3. 가상환경과 Jypyter kernel 연결\n",
    "\n",
    "   ```bash\n",
    "   # python -m ipykernel install --user --name \"가상환경이름\" --display-name \"노트북에 표시할 이름\"\n",
    "   python -m ipykernel install --user --name venv --display-name llm_venv\n",
    "   ```\n",
    "\n",
    "4. Jupyter (notebook or lab) 실행\n",
    "\n",
    "   ```bash\n",
    "   jupyter notebook\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import warnings\n",
    "import aiocsv\n",
    "import aiofiles\n",
    "import tiktoken\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "from functools import wraps\n",
    "from typing import Any, Coroutine, Generator, AsyncGenerator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# text 전처리\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.document_loaders.excel import UnstructuredExcelLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import (\n",
    "    create_retrieval_chain,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 클래스 정의\n",
    "- 훈련 데이터의 폴더와 Input용 데이터가 담긴 폴더의 경로를 인자로 넘겨야합니다.\n",
    "- Input 형태는 csv와 xlsx 엑셀파일만 가능합니다.\n",
    "    - 텍스트 형태의 데이터는 기사 단위(row단위)로 프로세스가 어려우므로 제외\n",
    "- 사용 가능 모델\n",
    "    - gpt-3.5-turbo\n",
    "    - gpt-4-turbo\n",
    "    - claude-2.1\n",
    "    - claude-3-haiku-20240307\n",
    "- 훈련 데이터 가능 확장자\n",
    "    - pdf, docx, txt, xlsx, csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_timer(func):\n",
    "    @wraps(func)\n",
    "    async def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # call the decorated function\n",
    "        result = await func(*args, **kwargs)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        if func.__name__ == \"main\":\n",
    "            print(f\"----------------------------------------\")\n",
    "            print(f\"---------- Main 함수 실행 --------------\")\n",
    "            print(f\"총 실행 시간: {execution_time:.3f}초\")\n",
    "            print(f\"----------------------------------------\")\n",
    "        else:\n",
    "            print(f\"----------------------------------------\")\n",
    "            print(f\"실행 시간: {execution_time:.3f}초\")\n",
    "            print(f\"----------------------------------------\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class LlmArticleClassifier:\n",
    "    def __init__(self, train_dir_path: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        self.train_dir_path = train_dir_path\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    async def async_get_input_data_from_files(\n",
    "        self, input_dir_path\n",
    "    ) -> AsyncGenerator[str, None]:\n",
    "        for file_name in glob.glob(input_dir_path + \"/*\"):\n",
    "            try:\n",
    "                if \".xlsx\" in file_name:\n",
    "                    data = pd.read_excel(file_name)\n",
    "                elif \".csv\" in file_name:\n",
    "                    data = pd.read_csv(file_name)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                for _, row in data.iterrows():\n",
    "                    row_dict = row.to_dict()\n",
    "                    row_str = \"\\n\".join(f'\"{k}\": \"{v}\"' for k, v in row_dict.items())\n",
    "                    yield row_str\n",
    "\n",
    "            except Exception:\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    def sync_get_input_data_from_files(self) -> Generator[str, None, None]:\n",
    "        # formatted_data_strings = []\n",
    "\n",
    "        for file_name in glob.glob(self.input_dir_path + \"/*\"):\n",
    "            try:\n",
    "                if \".xlsx\" in file_name:\n",
    "                    data = pd.read_excel(file_name)\n",
    "                elif \".csv\" in file_name:\n",
    "                    data = pd.read_csv(file_name)\n",
    "\n",
    "                for _, row in data.iterrows():\n",
    "                    row_dict = row.to_dict()\n",
    "                    row_str = \"\\n\".join(f'\"{k}\": \"{v}\"' for k, v in row_dict.items())\n",
    "                    # formatted_data_strings.append(row_str)\n",
    "                    yield row_str\n",
    "\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "        # return formatted_data_strings\n",
    "\n",
    "    def get_train_data_from_files(self) -> list[Document]:\n",
    "        doc_list = []\n",
    "\n",
    "        for file_name in glob.glob(self.train_dir_path + \"/*\"):\n",
    "            print(f\"Uploaded {file_name}\")\n",
    "\n",
    "            if \".pdf\" in file_name:\n",
    "                loader = PyPDFLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".docx\" in file_name:\n",
    "                loader = Docx2txtLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".txt\" in file_name:\n",
    "                loader = TextLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".xlsx\" in file_name:\n",
    "                loader = UnstructuredExcelLoader(file_name, mode=\"elements\")\n",
    "                documents = loader.load_and_split()\n",
    "            elif \".csv\" in file_name:\n",
    "                loader = CSVLoader(file_name)\n",
    "                documents = loader.load_and_split()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            doc_list.extend(documents)\n",
    "\n",
    "        return doc_list\n",
    "\n",
    "    def tiktoken_len(self, text: str) -> int:\n",
    "        tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens = tokenizer.encode(text)\n",
    "        return len(tokens)\n",
    "\n",
    "    def get_text_chunks(self) -> list[Document]:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1024, chunk_overlap=100, length_function=self.tiktoken_len\n",
    "        )\n",
    "        text = self.get_train_data_from_files()\n",
    "        chunks = text_splitter.split_documents(text)\n",
    "        return chunks\n",
    "\n",
    "    async def get_vectorstore(self) -> Coroutine[Any, Any, FAISS]:\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "        text_chunks = self.get_text_chunks()\n",
    "        vectordb = await FAISS.afrom_documents(text_chunks, embeddings)\n",
    "        return vectordb\n",
    "\n",
    "    def set_templetes(self):\n",
    "        document_template = f\"\"\"\n",
    "            너의 역할은 주어진 뉴스 기사나 리포트를 분석하고 제공된 Output 형식의 카테고리 분류 설명에 따라 \n",
    "            입력 기사를 카테고리별로 분류하는 역할이야.\n",
    "            결과를 출력할때는 Markdown에서 글씨를 보기 쉽게 문장 혹은 단위별로 prettify를 적용해서 출력해줘.\n",
    "            \n",
    "            리포트 혹은 뉴스의 내용과 Output 형식은 백틱(```)안에 주어진다.\n",
    "            예제 리포트에 포함된 내용은 결과에 Return하지 않는다.\n",
    "            \n",
    "            예제 리포트:\n",
    "            {{context}}\n",
    "            \n",
    "            ```\n",
    "            {{input}}\n",
    "            ```\n",
    "            \"\"\"\n",
    "        document_prompt = PromptTemplate(\n",
    "            template=document_template, input_variables=[\"input\"]\n",
    "        )\n",
    "\n",
    "        return document_prompt\n",
    "\n",
    "    async def get_create_retrieval_chain(self, temperature: float = 0.0):\n",
    "\n",
    "        if \"gpt\" in self.model:\n",
    "            llm = ChatOpenAI(\n",
    "                api_key=os.getenv(\"open_ai_key\"),\n",
    "                model_name=self.model,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "        elif \"claude\" in self.model:\n",
    "            llm = ChatAnthropic(\n",
    "                api_key=os.getenv(\"antrophic_key\"),\n",
    "                model_name=self.model,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever 옵션\n",
    "        as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5})\n",
    "        as_retriever(search_kwargs={\"k\": 3})\n",
    "        as_retriever(search_type=\"mmr\")\n",
    "        \"\"\"\n",
    "        vectorstore = await self.get_vectorstore()\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        document_prompt = self.set_templetes()\n",
    "\n",
    "        combine_docs_chain = create_stuff_documents_chain(llm, document_prompt)\n",
    "        retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "        return retrieval_chain\n",
    "\n",
    "    @async_timer\n",
    "    async def process_llm(self, query: str) -> str:\n",
    "        chain = await self.get_create_retrieval_chain()\n",
    "        result = await chain.ainvoke({\"input\": query})\n",
    "        print(result[\"answer\"])\n",
    "\n",
    "        return result\n",
    "\n",
    "    @async_timer\n",
    "    async def process_llm_batch(self, queries: list[str]) -> list[dict[str, str]]:\n",
    "        chain = await self.get_create_retrieval_chain()\n",
    "        results = await chain.abatch([{\"input\": query} for query in queries])\n",
    "        for result in results:\n",
    "            # print(f\"Query: {result['input']}\")\n",
    "            print(result['answer'])\n",
    "            print()\n",
    "        return results    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_to_csv(results: list[dict[str, str]]):\n",
    "\n",
    "    output_dir = \"./output_data\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, \"results.csv\")\n",
    "\n",
    "    async with aiofiles.open(\n",
    "        output_file, mode=\"w\", encoding=\"utf-8-sig\", newline=\"\"\n",
    "    ) as afp:\n",
    "        writer = aiocsv.AsyncWriter(afp, dialect=\"unix\")\n",
    "        # header\n",
    "        await writer.writerow([\"query\", \"answer\"])\n",
    "\n",
    "        # rows\n",
    "        for result in results:\n",
    "            await writer.writerow([result[\"input\"], result[\"answer\"]])\n",
    "\n",
    "    print(f\"결과가 '{output_file}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main 함수\n",
    "main 함수에서는 LlmArticleClassifier 클래스를 초기화하고, 입력 데이터를 가져와서 process_llm 메서드를 실행하는 방식으로 사용됩니다. 코드에서는 비동기 방식으로 데이터를 처리하고, 일정한 크기의 청크로 나누어 병렬로 처리하는 방식을 사용하고 있습니다.\n",
    "\n",
    "### main 함수의 동작 과정:\n",
    "\n",
    "1. LlmArticleClassifier 클래스를 초기화\n",
    "   - train_dir_path -> 훈련용 데이터 폴더 위치를 인자로 전달\n",
    "2. LlmArticleClassifier.async_get_input_data_from_files()\n",
    "   - 폴더에 있는 파일의 row단위를 input형태로 변환\n",
    "   - input_dir_path -> Input 폴더의 위치를 인자로 전달\n",
    "3. data_generator로부터 일정한 크기의 묶음으로 나누어 병렬로 처리\n",
    "   - chunk -> 병렬처리용 Thread 개수를 설정\n",
    "4. 각 청크에 대해 병렬로 결과 처리\n",
    "   - write_to_csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@async_timer\n",
    "async def main():\n",
    "    llm = LlmArticleClassifier(train_dir_path=\"./train_data\", model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    # 폴더 내의 모든 엑셀파일 인식\n",
    "    data_generator = llm.async_get_input_data_from_files(\n",
    "        input_dir_path=\"./input_data\",\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    chunk_size = 4  # 한 번에 처리할 chunk 크기\n",
    "    batch_queries = []\n",
    "    async for query in data_generator:\n",
    "        batch_queries.append(query)\n",
    "        if len(batch_queries) == chunk_size:\n",
    "            results.extend(await llm.process_llm_batch(batch_queries))\n",
    "            batch_queries.clear()\n",
    "\n",
    "    # 잔여 task가 있을경우 처리\n",
    "    if batch_queries:\n",
    "        results.extend(await llm.process_llm_batch(batch_queries))\n",
    "    \n",
    "    await write_to_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploaded .<span style=\"color: #800080; text-decoration-color: #800080\">/train_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">training_data.txt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploaded .\u001b[35m/train_data/\u001b[0m\u001b[95mtraining_data.txt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```\n",
       "제목: <span style=\"color: #008000; text-decoration-color: #008000\">'메가존클라우드, 데이터브릭스 최고 등급 ‘엘리트’ 파트너 선정'</span>\n",
       "언론사: 한국경제TV\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:57:28</span>\n",
       "대상기업: 메가존클라우드\n",
       "내용: \n",
       "    - 내용 소제목: 데이터브릭스 최고 등급 <span style=\"color: #008000; text-decoration-color: #008000\">'엘리트'</span> 파트너 선정\n",
       "    - 내용 요약: 메가존클라우드가 데이터브릭스의 최고 등급 <span style=\"color: #008000; text-decoration-color: #008000\">'엘리트'</span> 파트너로 선정되었으며, 이는 고객의 성공적인 \n",
       "디지털 전환을 이끄는 파트너에 부여되는 등급이다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 투자\n",
       "            - 수치: 2700명\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 매출\n",
       "            - 수치: 1조5106억원\n",
       "```\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```\n",
       "제목: \u001b[32m'메가존클라우드, 데이터브릭스 최고 등급 ‘엘리트’ 파트너 선정'\u001b[0m\n",
       "언론사: 한국경제TV\n",
       "발행일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m09:57:28\u001b[0m\n",
       "대상기업: 메가존클라우드\n",
       "내용: \n",
       "    - 내용 소제목: 데이터브릭스 최고 등급 \u001b[32m'엘리트'\u001b[0m 파트너 선정\n",
       "    - 내용 요약: 메가존클라우드가 데이터브릭스의 최고 등급 \u001b[32m'엘리트'\u001b[0m 파트너로 선정되었으며, 이는 고객의 성공적인 \n",
       "디지털 전환을 이끄는 파트너에 부여되는 등급이다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 투자\n",
       "            - 수치: 2700명\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 매출\n",
       "            - 수치: 1조5106억원\n",
       "```\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">제목: <span style=\"color: #008000; text-decoration-color: #008000\">'KT스카이라이프, 1분기 영업익 29억 원…전년比 82%↓'</span>\n",
       "언론사: 서울경제\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:03</span>\n",
       "대상기업: KT스카이라이프\n",
       "내용: \n",
       "    - 내용 소제목: 1분기 영업실적\n",
       "    - 내용 요약: KT스카이라이프는 올해 1분기에 영업이익 29억 원을 기록하며 전년 대비 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>% 감소했고, 매출액은 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>% \n",
       "증가한 2544억 원을 기록했다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 영업이익\n",
       "            - 수치: 29억 원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 매출액\n",
       "            - 수치: 2544억 원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 당기순이익\n",
       "            - 수치: 13억 원\n",
       "    - 내용 소제목: 영업이익 감소 이유\n",
       "    - 내용 요약: 영업이익이 줄어든 이유는 콘텐츠 투자 비용 증가와 방송 발전 기금, 프로그램 사용료 증가 등이 영향을 \n",
       "끼쳤다.\n",
       "    - 내용 소제목: 매출액 증가 이유\n",
       "    - 내용 요약: 인터넷과 모바일 가입자의 증가로 매출액이 증가했으며, skyTV, sky인터넷, 모바일 가입자가 전기 대비 \n",
       "약 6000명 증가했다.\n",
       "    - 내용 소제목: ENA 성장\n",
       "    - 내용 요약: KT스카이라이프의 방송 채널인 ENA가 성장하며 시청률 순위 8위를 기록했고, 광고 수익도 증가했다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 시청률 순위\n",
       "            - 수치: 8위\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 광고 수익\n",
       "            - 수치: 역대 최대 규모\n",
       "</pre>\n"
      ],
      "text/plain": [
       "제목: \u001b[32m'KT스카이라이프, 1분기 영업익 29억 원…전년比 82%↓'\u001b[0m\n",
       "언론사: 서울경제\n",
       "발행일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m09:56:03\u001b[0m\n",
       "대상기업: KT스카이라이프\n",
       "내용: \n",
       "    - 내용 소제목: 1분기 영업실적\n",
       "    - 내용 요약: KT스카이라이프는 올해 1분기에 영업이익 29억 원을 기록하며 전년 대비 \u001b[1;36m82\u001b[0m% 감소했고, 매출액은 \u001b[1;36m2\u001b[0m% \n",
       "증가한 2544억 원을 기록했다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 영업이익\n",
       "            - 수치: 29억 원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 매출액\n",
       "            - 수치: 2544억 원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 당기순이익\n",
       "            - 수치: 13억 원\n",
       "    - 내용 소제목: 영업이익 감소 이유\n",
       "    - 내용 요약: 영업이익이 줄어든 이유는 콘텐츠 투자 비용 증가와 방송 발전 기금, 프로그램 사용료 증가 등이 영향을 \n",
       "끼쳤다.\n",
       "    - 내용 소제목: 매출액 증가 이유\n",
       "    - 내용 요약: 인터넷과 모바일 가입자의 증가로 매출액이 증가했으며, skyTV, sky인터넷, 모바일 가입자가 전기 대비 \n",
       "약 6000명 증가했다.\n",
       "    - 내용 소제목: ENA 성장\n",
       "    - 내용 요약: KT스카이라이프의 방송 채널인 ENA가 성장하며 시청률 순위 8위를 기록했고, 광고 수익도 증가했다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 시청률 순위\n",
       "            - 수치: 8위\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 광고 수익\n",
       "            - 수치: 역대 최대 규모\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```\n",
       "제목: <span style=\"color: #008000; text-decoration-color: #008000\">\"'인공지능?' '아니 공감지능!'…LG 올레드 에보, 50년 전 김환기 작품 소환\"</span>\n",
       "언론사: 데일리안\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:10</span>\n",
       "대상기업: LG전자\n",
       "내용: \n",
       "    - 내용 소제목: LG 올레드 에보 소개\n",
       "    - 내용 요약: LG 올레드 에보가 한국 대표 미술가 김환기의 작품을 미국 뉴욕에서 선보이는 <span style=\"color: #008000; text-decoration-color: #008000\">'디지털 캔버스'</span>로 \n",
       "활약하며, 김환기의 미술 세계를 재조명하고 있다.\n",
       "    - 내용 소제목: 미디어아트 전시\n",
       "    - 내용 요약: LG전자의 <span style=\"color: #008000; text-decoration-color: #008000\">'공감지능(AI) TV '</span>LG 올레드 에보'를 통해 김환기의 대표작을 재해석한 미디어아트가 \n",
       "전시되며, 김환기의 작품을 미디어아트로 표현한다.\n",
       "    - 내용 소제목: LG 올레드 에보 기능\n",
       "    - 내용 요약: LG 올레드 에보는 AI 화질‧음질 프로세서 <span style=\"color: #008000; text-decoration-color: #008000\">'알파11'</span>을 탑재하고 있으며, 사용자의 취향을 스스로 파악하여\n",
       "화질과 음질을 최적화하고, AI 챗봇 기능을 통해 사용자에게 맞춤형 서비스를 제공한다.\n",
       "```\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```\n",
       "제목: \u001b[32m\"'인공지능?' '아니 공감지능!'…LG 올레드 에보, 50년 전 김환기 작품 소환\"\u001b[0m\n",
       "언론사: 데일리안\n",
       "발행일자: \u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m10:00:10\u001b[0m\n",
       "대상기업: LG전자\n",
       "내용: \n",
       "    - 내용 소제목: LG 올레드 에보 소개\n",
       "    - 내용 요약: LG 올레드 에보가 한국 대표 미술가 김환기의 작품을 미국 뉴욕에서 선보이는 \u001b[32m'디지털 캔버스'\u001b[0m로 \n",
       "활약하며, 김환기의 미술 세계를 재조명하고 있다.\n",
       "    - 내용 소제목: 미디어아트 전시\n",
       "    - 내용 요약: LG전자의 \u001b[32m'공감지능\u001b[0m\u001b[32m(\u001b[0m\u001b[32mAI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m TV '\u001b[0mLG 올레드 에보'를 통해 김환기의 대표작을 재해석한 미디어아트가 \n",
       "전시되며, 김환기의 작품을 미디어아트로 표현한다.\n",
       "    - 내용 소제목: LG 올레드 에보 기능\n",
       "    - 내용 요약: LG 올레드 에보는 AI 화질‧음질 프로세서 \u001b[32m'알파11'\u001b[0m을 탑재하고 있으며, 사용자의 취향을 스스로 파악하여\n",
       "화질과 음질을 최적화하고, AI 챗봇 기능을 통해 사용자에게 맞춤형 서비스를 제공한다.\n",
       "```\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">제목: <span style=\"color: #008000; text-decoration-color: #008000\">'팹리스 업체'</span> 퓨리오사AI, 2000억 투자 유치 추진\n",
       "언론사: thebell\n",
       "발행일자: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20230119</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:05:04</span>\n",
       "대상기업: 퓨리오사AI\n",
       "내용: \n",
       "    - 내용 소제목: 퓨리오사AI, 최대 2000억 투자 유치 추진\n",
       "    - 내용 요약: 퓨리오사AI가 최대 2000억원 규모의 투자 유치를 추진 중이며, 산은과 DSC인베스트먼트 등이 투자 참여 \n",
       "예정이다. 이번 투자로 퓨리오사AI는 유니콘 기업으로 등극할 전망이다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 시리즈C 투자 규모\n",
       "            - 수치: 2000억원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 기업가치\n",
       "            - 수치: 8000억원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 이전 투자 규모\n",
       "            - 수치: 800억원\n",
       "</pre>\n"
      ],
      "text/plain": [
       "제목: \u001b[32m'팹리스 업체'\u001b[0m 퓨리오사AI, 2000억 투자 유치 추진\n",
       "언론사: thebell\n",
       "발행일자: \u001b[1;36m20230119\u001b[0m \u001b[1;92m08:05:04\u001b[0m\n",
       "대상기업: 퓨리오사AI\n",
       "내용: \n",
       "    - 내용 소제목: 퓨리오사AI, 최대 2000억 투자 유치 추진\n",
       "    - 내용 요약: 퓨리오사AI가 최대 2000억원 규모의 투자 유치를 추진 중이며, 산은과 DSC인베스트먼트 등이 투자 참여 \n",
       "예정이다. 이번 투자로 퓨리오사AI는 유니콘 기업으로 등극할 전망이다.\n",
       "        - 수치 요약1: \n",
       "            - 수치 내용: 시리즈C 투자 규모\n",
       "            - 수치: 2000억원\n",
       "        - 수치 요약2: \n",
       "            - 수치 내용: 기업가치\n",
       "            - 수치: 8000억원\n",
       "        - 수치 요약3: \n",
       "            - 수치 내용: 이전 투자 규모\n",
       "            - 수치: 800억원\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">실행 시간: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42.</span>219초\n",
       "</pre>\n"
      ],
      "text/plain": [
       "실행 시간: \u001b[1;36m42.\u001b[0m219초\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">결과가 <span style=\"color: #008000; text-decoration-color: #008000\">'./output_data/results.csv'</span>에 저장되었습니다.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "결과가 \u001b[32m'./output_data/results.csv'\u001b[0m에 저장되었습니다.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---------- Main 함수 실행 --------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---------- Main 함수 실행 --------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">총 실행 시간: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>127초\n",
       "</pre>\n"
      ],
      "text/plain": [
       "총 실행 시간: \u001b[1;36m43.\u001b[0m127초\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
